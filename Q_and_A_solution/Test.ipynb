{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install tensorflow_text>=2.0.0rc0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import tensorflow_text\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "#the commented code is to experiment with caching the module\n",
    "# os.environ['TFHUB_CACHE_DIR'] = '/Users/zakikidane/Documents/Advice_AI/Q_and_A_solution' #Any folder that you can access\n",
    "# elmo_model = hub.Module('https://tfhub.dev/google/universal-sentence-encoder/4', trainable=True)\n",
    "# # Load the model\n",
    "module = hub.load('https://tfhub.dev/google/universal-sentence-encoder-qa/3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadFile(filepath):\n",
    "    with open(filepath, \"r\") as f: lines = f.readlines()\n",
    "    lines = [line[:-2] for line in lines] # removes the newlines at the end\n",
    "    return lines\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(query, lines):\n",
    "  # Encode the question (or more aptly an array of the single function)\n",
    "    advice = tf.constant(lines)\n",
    "    advice_embeddings = module.signatures['response_encoder'](\n",
    "    input=advice,context=advice) \n",
    "    question_embeddings = module.signatures['question_encoder'](tf.constant([query]))\n",
    "\n",
    "    # Get an array of floats for how \"good\" each adivce is for this query\n",
    "    # We can do this via dot product because math\n",
    "    # (and this is secretly a similarity problem)\n",
    "    weights = np.inner(question_embeddings['outputs'],\n",
    "                     advice_embeddings['outputs'])[0] # [0] because just one query\n",
    "\n",
    "  # Returns a sorted tuple list with advice and\n",
    "  # how \"good\" they are for the given query\n",
    "    return sorted([(lines[i], weights[i]) for i in range(len(lines))], key=lambda x: -x[1])\n",
    "\n",
    "def testFiles(query, filepath):\n",
    "    lines = loadFile(filepath)\n",
    "    n = 3\n",
    "    results = list(ask(query, lines)[:n])\n",
    "    #print('For advice file of {} the score is {} .'.format(filepath, sum(r[1] for r in results)))\n",
    "    val = sum(r[1] for r in results)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score is 0.5704040080308914\n",
      "score is 0.6048931777477264\n",
      "score is 0.28732863813638687\n",
      "score is 0.1236298717558384\n",
      "score is 0.9196281731128693\n",
      "score is 1.0333175957202911\n",
      "score is 0.6869828104972839\n",
      "score is 0.6787922084331512\n",
      "score is 0.9357615411281586\n",
      "score is 0.4119967073202133\n",
      "score is 0.1684480793774128\n",
      "score is 0.9635390043258667\n",
      "score is 1.528080403804779\n",
      "score is 0.8309200257062912\n"
     ]
    }
   ],
   "source": [
    "files = [\"../data/advice.txt\", \"../data/heyfromthefuture/filtered.txt\"]\n",
    "queries = [\"im overweight\", \"my girlfriend left me\", \"I Am sadd\", \"I am Happo\", \"why is life so hard\",\"How do I pay off my debt?\",\"I don't want children\"]\n",
    "scores = {files[0]:[], files[1]:[]}\n",
    "\n",
    "for file in files: \n",
    "    for query in queries:\n",
    "        score = testFiles(query, file)\n",
    "        print('score is', score)\n",
    "        scores[file].append(score)\n",
    "         \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'../data/advice.txt': [0.5704040080308914, 0.6048931777477264, 0.28732863813638687, 0.1236298717558384, 0.9196281731128693, 1.0333175957202911, 0.6869828104972839], '../data/heyfromthefuture/filtered.txt': [0.6787922084331512, 0.9357615411281586, 0.4119967073202133, 0.1684480793774128, 0.9635390043258667, 1.528080403804779, 0.8309200257062912]}\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
