{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q and A",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rjLs4af8CXd"
      },
      "source": [
        "# Load the advice dataset\r\n",
        "with open(\"filtered.txt\", \"r\") as f: lines = f.readlines()\r\n",
        "lines = [line[:-2] for line in lines] # removes the newlines at the end"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPDrz63dd6da"
      },
      "source": [
        "!pip3 install tensorflow_text>=2.0.0rc0"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUeZI9yXd3Tt"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import tensorflow_hub as hub\r\n",
        "import numpy as np\r\n",
        "import tensorflow_text\r\n",
        "\r\n",
        "# Load the model\r\n",
        "module = hub.load('https://tfhub.dev/google/universal-sentence-encoder-qa/3')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI0QG1_FiofS"
      },
      "source": [
        "# Encode advice as responses\r\n",
        "advice = tf.constant(lines)\r\n",
        "advice_embeddings = module.signatures['response_encoder'](\r\n",
        "    input=advice,context=advice) # Not sure what context is supposed to be but\r\n",
        "                                 # putting the same thing for both seems to work"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40Cy7KXrgby8"
      },
      "source": [
        "# Returns a sorted tuple list with advice and\r\n",
        "# how \"good\" they are for the given query\r\n",
        "def ask(query):\r\n",
        "  # Encode the question (or more aptly an array of the single function)\r\n",
        "  question_embeddings = module.signatures['question_encoder'](tf.constant([query]))\r\n",
        "\r\n",
        "  # Get an array of floats for how \"good\" each adivce is for this query\r\n",
        "  # We can do this via dot product because math\r\n",
        "  # (and this is secretly a simmilarity problem)\r\n",
        "  weights = np.inner(question_embeddings['outputs'],\r\n",
        "                     advice_embeddings['outputs'])[0] # [0] because just one query\r\n",
        "\r\n",
        "  # Returns a sorted tuple list with advice and\r\n",
        "  # how \"good\" they are for the given query\r\n",
        "  return sorted([(lines[i], weights[i]) for i in range(len(lines))], key=lambda x: -x[1])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CxX6sCMg3fO",
        "outputId": "6bd856d9-5554-4105-e735-20d56842307f"
      },
      "source": [
        "# What question do you ask! This is simmilar to what our final user would enter\r\n",
        "query = \"What should I do if my girlfriend just broke up with me?\"\r\n",
        "# Gets the top `n` responses\r\n",
        "n = 10\r\n",
        "\r\n",
        "# Does the do\r\n",
        "print(ask(query)[:n])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(\"Take time to mourn what you've lost\", 0.3374713), ('Have a good appetite, lots of friends, and keep busy', 0.31954515), ('Make time to cry', 0.31370622), ('Try not to let a week go by without having lunch or coffee with a friend', 0.2796944), ('Keep busy doing what you like', 0.2751931), ('Spend more time doing for those who can do nothing for you', 0.25344852), (\"Get to acceptance as fast as possible. By acceptance, I mean welcome everything that happens in your life. The best time to prepare for a crisis is before it comes. An overreaction is an indication you either didn't prepare or lack imagination [to think this couldn't happen]\", 0.24635218), (\"Have a pet. Life gets lonely sometimes. Pets are reminders of how we're all living things\", 0.23694426), (\"Focus more on the present - Don't regret the past and don't be anxious about the future. Appreciate what is happening right now\", 0.23319468), ('Forgive yourself for your mistakes', 0.2330167)]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}